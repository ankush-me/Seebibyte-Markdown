*	#		Computer Vision Software “Show and Tell”
	##		Information Engineering Building, Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ
	###		Thursday 15th June 2017, 11.00-15.30
	####	The purpose of the Show and Tell is to demonstrate software for searching, annotating and categorizing images in (potentially) large datasets. Software is open source and will be available following the meeting.
	#####	ST15617
	
	[seebibyte@gmail.com](mailto:seebibyte@gmail.com)
	[Map](https://www.google.co.uk/maps/@51.758504,-1.260467,16z)
	
	10.30
	:	Coffee and pastries
	
	11.00-13.00
	:	 Presentations (check here for updates)
		*   Image Matching
		*   Image Comparator
		*   Case study
		*   Image Classification
		*   Image Annotation
		*   Image Generation
	
		Presenters
		Dr Giles Bergel, Dr Ernesto Coto, Dr Abhishek Dutta,Professor Alison Noble, Professor Andrea Vedaldi, Professor Andrew Zisserman

	13.00 
	:	Vegetarian lunch
	
	14.00-15.30
	:	Individual discussions with PI’s (optional, to be arranged on the day)
	
	15.30 
	:	Close
	
*	#		Computer Vision Software “Show and Tell”
	##		Department of Engineering Science
	###		Tuesday 14th June 2016, 11.00-16.00
	####	The Department of Engineering Science’s Seebibyte Project is holding a "Show and Tell" to introduce and demonstrate advanced machine learning methods that enable automated analysis of image and video data across research disciplines. This session will focus on work developed by Andrew Zisserman, Alison Noble, and Andrea Vedaldi. 
	#####	ST14616
	
	[Penny Farrar, Seebibyte Project Manager](mailto:penny.farrar@eng.ox.ac.uk)
	
	11.00-13.00
	:	We will demonstrate software developed by the Visual Geometry Group, and advise how it can immediately be applied
		to your own projects. The presentations will cover the following topics
		1. **Counting**: Counting the number of instances of an object in images is a task commonly required across various
		scientific fields, such as biology, histopathology, material sciences and zoology. We will demonstrate our existing
		software framework, which enables counting objects in large image databases by learning from the users what the
		objects of interests are - such as specific cells, crystals or animals.
		2. **Landmark Detection**: Landmarks indicate salient points in an image. For example, human body joint locations
		determine body posture in an image; and road junction and intersection locations partially determine road layout in
		aerial images. Landmarks such as these can be accurately predicted using deep learning methods.
		3. **Segmentation**: Every pixel in an image carries a meaning, which image segmentation can extract automatically. For
		example, an image of the Earth can be partitioned into buildings, roads, green areas, forests, rocks, rivers, lakes, and
		sea. These features can not only be recognized, but also accurately delineated, extracting information such as their
		shape and extent. Furthermore, every part of the image is associated with a label, leaving nothing unaccounted for.
		4. **Text Spotting**: A surprising amount of information can be extracted from text contained in images, from street signs in
		an urban scene, to labels on objects such as books, consumer product wrappings, or tags. While traditional OCR can
		only extract text scanned with the goal of automatic recognition, state-of-the-art deep learning methods work in any
		image or video, opening many new applications of this technology.
		
	13.00-14.00
	:	Lunch provided
	
	14.00 to 16.00
	:	This session is aimed at short (30 min) one-to-one meetings to discuss in detail how the software might be developed for
		particular projects. Meetings will be scheduled over lunch for the afternoon sessions.

	
	